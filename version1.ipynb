{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240dc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:42:23,691 - INFO - Successfully loaded 1827 chunks.\n",
      "2025-06-26 22:42:23,693 - INFO - Generating embeddings for chunks...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 1827 chunks from transcripts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:42:24,115 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:25,131 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:25,817 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:26,486 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:27,264 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:27,637 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:28,919 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:29,559 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:30,241 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:30,610 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:31,466 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:32,170 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:32,704 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:33,234 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:34,056 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:34,435 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:34,811 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:35,484 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:35,977 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:36,362 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:36,690 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:37,505 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:38,133 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:38,671 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:39,002 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:39,545 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:40,259 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:40,946 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:41,762 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:42,057 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:42,720 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:43,173 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:43,870 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:44,277 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:45,048 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:45,557 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:45,938 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:42:46,335 - INFO - Generated 1827 chunk embeddings.\n",
      "2025-06-26 22:42:46,338 - INFO - Setting up LangChain Agent...\n",
      "2025-06-26 22:42:46,488 - INFO - LangChain Agent setup complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Financial Literacy Chatbot (LangChain Agent Demo). Type 'exit' to quit.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:45:01,646 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-06-26 22:45:02,014 - INFO - Tool 'calculate_debt_details' called with input: principal=12000, interest_rate=8, monthly_payment=250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `DebtCalculator` with `principal=12000, interest_rate=8, monthly_payment=250`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mTo pay off a principal of $12,000.00 with an annual interest rate of 8.0% and a monthly payment of $250.00:\n",
      "- Estimated time to pay off: 59 months (4.9 years)\n",
      "- Estimated total interest paid: $2,750.00\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:45:02,558 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mTo pay off your $12,000 loan at an 8% interest rate with monthly payments of $250, it will take approximately 59 months (or about 4.9 years). Over this period, you will pay an estimated total interest of $2,750.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "ðŸ’¬ Chatbot:\n",
      "To pay off your $12,000 loan at an 8% interest rate with monthly payments of $250, it will take approximately 59 months (or about 4.9 years). Over this period, you will pay an estimated total interest of $2,750.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() # This line is crucial for loading your .env file\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Assuming prepare_chunks.py is a separate file that you control\n",
    "from prepare_chunks import read_and_chunk_transcripts\n",
    "import logging\n",
    "import re # For parsing numbers from input string\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent # Changed to create_openai_tools_agent\n",
    "from langchain.tools import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage # Added SystemMessage\n",
    "\n",
    "\n",
    "# Configure logging for better debugging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize OpenAI client. It's good practice to get API key from environment.\n",
    "# Ensure OPENAI_API_KEY is set in your environment variables.\n",
    "try:\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    if not client.api_key:\n",
    "        raise ValueError(\"OPENAI_API_KEY environment variable not set.\")\n",
    "except ValueError as e:\n",
    "    logging.error(f\"Configuration Error: {e}\")\n",
    "    # Exit or handle gracefully if API key is missing\n",
    "    exit(\"Exiting: OpenAI API key is missing. Please set OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "\n",
    "# --- 1. Improve Chunking Strategy (Conceptual Change, implement in prepare_chunks.py) ---\n",
    "# The way you chunk transcripts is critical. If chunks are too small, they lack context.\n",
    "# If too large, they might contain irrelevant info diluting the similarity.\n",
    "# Suggestions for `prepare_chunks.py`:\n",
    "# A. Fixed size with overlap: e.g., 500 characters per chunk with 100 characters overlap.\n",
    "#    This helps maintain context across chunk boundaries.\n",
    "# B. Sentence-based chunking: Ensure chunks don't cut sentences in half.\n",
    "# C. Paragraph-based chunking: If transcripts are paragraphed, use paragraphs as chunks.\n",
    "# D. Recursive character text splitter (LangChain concept): Splits by paragraphs, then sentences, then words, etc.\n",
    "#    This is more advanced but often yields better results.\n",
    "# Make sure your `read_and_chunk_transcripts` function handles this effectively.\n",
    "try:\n",
    "    chunks = read_and_chunk_transcripts('transcripts/')\n",
    "    if not chunks:\n",
    "        logging.warning(\"No chunks read from 'transcripts/'. Ensure files exist and content is processed.\")\n",
    "        # Handle case where no chunks are loaded, e.g., exit or use dummy data\n",
    "        exit(\"Exiting: No transcript chunks found. Please check 'transcripts/' directory and prepare_chunks.py.\")\n",
    "    logging.info(f\"Successfully loaded {len(chunks)} chunks.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error reading and chunking transcripts: {e}\")\n",
    "    exit(\"Exiting: Failed to process transcripts. Check 'prepare_chunks.py' and 'transcripts/' directory.\")\n",
    "\n",
    "\n",
    "def embed_texts(texts, model=\"text-embedding-ada-002\", batch_size=50):\n",
    "    \"\"\"\n",
    "    Generates embeddings for a list of texts using OpenAI's embedding API.\n",
    "    Handles batching and includes basic error handling.\n",
    "    \"\"\"\n",
    "    if not texts:\n",
    "        return []\n",
    "\n",
    "    embeddings = []\n",
    "    # Add a retry mechanism for robustness\n",
    "    max_retries = 3\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = client.embeddings.create(\n",
    "                    model=model,\n",
    "                    input=batch\n",
    "                )\n",
    "                embeddings.extend([item.embedding for item in response.data])\n",
    "                break # Break out of retry loop on success\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Embedding API error on batch {i//batch_size + 1}, attempt {attempt + 1}: {e}\")\n",
    "                if attempt == max_retries - 1:\n",
    "                    logging.error(f\"Max retries reached for embedding batch {i//batch_size + 1}. Skipping batch.\")\n",
    "                    # Optionally, append dummy embeddings or raise the error\n",
    "                # Add a small delay before retrying\n",
    "                import time\n",
    "                time.sleep(1 + attempt * 2) # Exponential backoff\n",
    "    return embeddings\n",
    "\n",
    "logging.info(\"Generating embeddings for chunks...\")\n",
    "chunk_embeddings = embed_texts(chunks)\n",
    "if not chunk_embeddings:\n",
    "    logging.error(\"Failed to generate embeddings for chunks. Check API key and network.\")\n",
    "    exit(\"Exiting: No chunk embeddings generated.\")\n",
    "logging.info(f\"Generated {len(chunk_embeddings)} chunk embeddings.\")\n",
    "\n",
    "\n",
    "# --- Modified function to be used as a LangChain Tool ---\n",
    "def retrieve_and_answer(query: str, top_k: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Retrieves relevant chunks from the loaded knowledge base and uses an LLM\n",
    "    to answer the query. This function is designed to be called as a LangChain Tool.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's question about financial literacy.\n",
    "        top_k (int): The number of top similar chunks to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        str: The AI's answer based on the retrieved context, or an error message.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Tool 'retrieve_and_answer' received query: '{query}'\")\n",
    "\n",
    "    if not query.strip():\n",
    "        return \"Please provide a non-empty question for the retrieval tool.\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = embed_texts([query])\n",
    "    if not query_embedding:\n",
    "        logging.error(\"Failed to generate embedding for the query within the tool.\")\n",
    "        return \"Sorry, I couldn't process your question for retrieval at the moment.\"\n",
    "    query_embedding = query_embedding[0]\n",
    "\n",
    "    # Calculate similarities and get top_k indices\n",
    "    similarities = cosine_similarity([query_embedding], chunk_embeddings)[0]\n",
    "    effective_top_k = min(top_k, len(chunks))\n",
    "    top_indices = np.argsort(similarities)[-effective_top_k:][::-1]\n",
    "\n",
    "    context_parts = []\n",
    "    for i in top_indices:\n",
    "        context_parts.append(f\"<DOCUMENT_START id={i}>\\n{chunks[i]}\\n<DOCUMENT_END>\")\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    logging.info(f\"\\nðŸ”Ž Retrieved top {effective_top_k} chunks (indices: {[int(i) for i in top_indices]}) for tool:\\n{context[:500]}...\\n\") # Log truncated context\n",
    "\n",
    "    # Prompt for GPT, specifically tailored for the tool's interaction with the LLM\n",
    "    # Note: The main agent's prompt will guide the overall conversation.\n",
    "    tool_llm_prompt = f\"\"\"You are a financial literacy expert. Your goal is to answer questions using ONLY the provided context.\n",
    "If the answer is not directly available or cannot be reasonably inferred from the context, state that you cannot answer based on the provided information.\n",
    "\n",
    "<RETRIEVED_DOCUMENTS>\n",
    "{context}\n",
    "</RETRIEVED_DOCUMENTS>\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    logging.info(\"Calling LLM from within 'retrieve_and_answer' tool...\")\n",
    "    try:\n",
    "        # Use the same client instance to avoid re-initializing\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\", # Using gpt-4o as specified in original answer_query\n",
    "            messages=[{\"role\": \"user\", \"content\": tool_llm_prompt}],\n",
    "            temperature=0.5, # Consistent with previous setting\n",
    "            max_tokens=700, # Consistent with previous setting\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip()\n",
    "        logging.info(\"LLM response received by tool.\")\n",
    "        # If the LLM produces the \"I don't know\" phrase, standardize it for the agent\n",
    "        if \"i apologize, but i don't have enough information\" in answer.lower() or \\\n",
    "           \"cannot answer based on the provided information\" in answer.lower():\n",
    "            return \"No sufficient information found in the knowledge base to answer that.\"\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error calling LLM API from tool: {e}\")\n",
    "        return \"Internal tool error: Could not generate an answer.\"\n",
    "\n",
    "# --- New and Modified Tool Functions with Calculation Capabilities ---\n",
    "\n",
    "def calculate_debt_details(input_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculates estimated time to pay off a debt and total interest paid based on\n",
    "    principal, annual interest rate, and monthly payment.\n",
    "    Input format expected: \"principal=<amount>, interest_rate=<percentage>, monthly_payment=<amount>\"\n",
    "    \"\"\"\n",
    "    logging.info(f\"Tool 'calculate_debt_details' called with input: {input_str}\")\n",
    "    principal = None\n",
    "    annual_interest_rate = None\n",
    "    monthly_payment = None\n",
    "\n",
    "    # Attempt to parse inputs\n",
    "    principal_match = re.search(r\"principal[=\\s]*(\\d[\\d,\\.]*)\", input_str, re.IGNORECASE)\n",
    "    rate_match = re.search(r\"interest_rate[=\\s]*(\\d[\\d,\\.]*)\", input_str, re.IGNORECASE)\n",
    "    payment_match = re.search(r\"monthly_payment[=\\s]*(\\d[\\d,\\.]*)\", input_str, re.IGNORECASE)\n",
    "\n",
    "    if principal_match:\n",
    "        try: principal = float(principal_match.group(1).replace(',', ''))\n",
    "        except ValueError: pass\n",
    "    if rate_match:\n",
    "        try: annual_interest_rate = float(rate_match.group(1).replace(',', ''))\n",
    "        except ValueError: pass\n",
    "    if payment_match:\n",
    "        try: monthly_payment = float(payment_match.group(1).replace(',', ''))\n",
    "        except ValueError: pass\n",
    "\n",
    "    if None in [principal, annual_interest_rate, monthly_payment]:\n",
    "        return (\n",
    "            \"To calculate debt details, I need the loan principal, the annual interest rate (as a percentage), \"\n",
    "            \"and your monthly payment. \"\n",
    "            \"Please provide them, for example: 'principal=10000, interest_rate=5, monthly_payment=200'.\"\n",
    "        )\n",
    "\n",
    "    if principal <= 0 or annual_interest_rate < 0 or monthly_payment <= 0:\n",
    "        return \"All input values (principal, interest rate, monthly payment) must be positive.\"\n",
    "\n",
    "    # Convert annual rate to monthly decimal rate\n",
    "    monthly_interest_rate = (annual_interest_rate / 100) / 12\n",
    "\n",
    "    if monthly_payment <= (principal * monthly_interest_rate) and annual_interest_rate > 0:\n",
    "        return \"Your monthly payment is too low to ever pay off the principal, or just covers interest. You might need to increase your payment to see progress.\"\n",
    "\n",
    "    # --- Amortization Calculation ---\n",
    "    remaining_def recommend_savings(input_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Provides savings recommendations. If monthly income and spending are provided,\n",
    "    it calculates a recommended 20% savings. Otherwise, it gives general guidelines\n",
    "    and prompts for input.\n",
    "    Input format expected: \"income=<amount>, spending=<amount>\" or just a general query.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Tool 'recommend_savings' called with input: {input_str}\")\n",
    "    income = None\n",
    "    spending = None\n",
    "\n",
    "    # Attempt to parse income and spending from the input string\n",
    "    income_match = re.search(r\"income[=\\s]*(\\d[\\d,\\.]*)\", input_str, re.IGNORECASE)\n",
    "    spending_match = re.search(r\"spending[=\\s]*(\\d[\\d,\\.]*)\", input_str, re.IGNORECASE)\n",
    "\n",
    "    if income_match:\n",
    "        try:\n",
    "            income = float(income_match.group(1).replace(',', ''))\n",
    "        except ValueError:\n",
    "            pass # Keep income as None if parsing fails\n",
    "    if spending_match:\n",
    "        try:\n",
    "            spending = float(spending_match.group(1).replace(',', ''))\n",
    "        except ValueError:\n",
    "            pass # Keep spending as None if parsing fails\n",
    "\n",
    "    if income is not None and spending is not None:\n",
    "        if income < 0 or spending < 0:\n",
    "            return \"Income and spending must be non-negative values.\"\n",
    "        if spending > income:\n",
    "            return \"Your spending seems to exceed your income. While saving is important, focusing on reducing spending or increasing income might be your first step.\"\n",
    "\n",
    "        # Calculate based on 50/30/20 rule (20% for savings and debt repayment)\n",
    "        recommended_savings = 0.20 * income\n",
    "        remaining_after_savings = income - recommended_savings\n",
    "\n",
    "        # Basic check for funds for needs/wants if 20% is saved\n",
    "        needs_wants_budget = 0.80 * income\n",
    "\n",
    "        return (\n",
    "            f\"Based on your monthly income of ${income:,.2f} and spending of ${spending:,.2f}:\\n\"\n",
    "            f\"Following the 50/30/20 rule, a recommended monthly savings amount (including debt repayment) is ${recommended_savings:,.2f} (20% of income).\\n\"\n",
    "            f\"This would leave ${needs_wants_budget:,.2f} for your needs and wants.\\n\"\n",
    "            \"Remember, consistency is key, and even small amounts add up over time.\"\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            \"To give you a personalized savings recommendation, I need your monthly income and average monthly spending. \"\n",
    "            \"A common guideline is the 50/30/20 rule: 50% for needs, 30% for wants, and 20% for savings and debt repayment. \"\n",
    "            \"Please provide your monthly income and spending, for example: 'my income is 3000 and spending is 2000'.\"\n",
    "        )\n",
    "\n",
    "def get_budgeting_templates(input_str: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Describes common budgeting templates and methods.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Tool 'get_budgeting_templates' called with input: {input_str}\")\n",
    "    return (\n",
    "        \"Budgeting templates can help you organize your finances. Common methods include:\\n\"\n",
    "        \"- **Spreadsheets:** Excel or Google Sheets offer great flexibility for custom budgets. \"\n",
    "        \"You can find many free templates online.\\n\"\n",
    "        \"- **Budgeting Apps:** Apps like Mint, YNAB (You Need A Budget), or Personal Capital offer \"\n",
    "        \"features like transaction tracking, goal setting, and visual reports.\\n\"\n",
    "        \"- **Pen and Paper:** A simple notebook can also work for tracking income and expenses.\\n\"\n",
    "        \"The key is to choose a method that you find easy to use and stick with.\"\n",
    "    )\n",
    "\n",
    "def get_expense_tracker_info(input_str: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Explains what an expense tracker is and its benefits.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Tool 'get_expense_tracker_info' called with input: {input_str}\")\n",
    "    return (\n",
    "        \"An expense tracker helps you monitor where your money goes. Its benefits include:\\n\"\n",
    "        \"- **Understanding Spending Habits:** Reveals where you might be overspending.\\n\"\n",
    "        \"- **Budget Adherence:** Helps you stick to your budget and identify areas for adjustment.\\n\"\n",
    "        \"- **Financial Goal Achievement:** By seeing your spending, you can find more money for savings or debt.\\n\"\n",
    "        \"- **Tax Preparation:** Makes it easier to categorize expenses for tax purposes.\\n\"\n",
    "        \"Methods range from manual logging to using sophisticated apps.\"\n",
    "    )\n",
    "\n",
    "principal = principal\n",
    "    total_interest_paid = 0\n",
    "    months = 0\n",
    "    max_months = 600 # Cap to prevent infinite loops for very low payments (50 years)\n",
    "\n",
    "    while remaining_principal > 0 and months < max_months:\n",
    "        interest_for_month = remaining_principal * monthly_interest_rate\n",
    "        principal_paid_this_month = monthly_payment - interest_for_month\n",
    "\n",
    "        if principal_paid_this_month <= 0 and remaining_principal > 0:\n",
    "            # Payment is not reducing principal, or only barely\n",
    "            return \"With these inputs, it seems your monthly payment is not sufficient to pay off the principal within a reasonable timeframe (e.g., it only covers interest). You may need to increase your payment.\"\n",
    "\n",
    "        remaining_principal -= principal_paid_this_month\n",
    "        total_interest_paid += interest_for_month\n",
    "        months += 1\n",
    "\n",
    "        # Adjust last payment if remaining principal is very small negative due to floating point\n",
    "        if remaining_principal < 0.01:\n",
    "            # This handles cases where the last payment slightly overpays\n",
    "            principal_paid_this_month += remaining_principal # Subtract the negative to add back\n",
    "            total_interest_paid -= remaining_principal # Adjust total interest too\n",
    "            remaining_principal = 0\n",
    "\n",
    "\n",
    "    if remaining_principal > 0: # If loop exited due to max_months\n",
    "        return (\n",
    "            f\"It would take more than {max_months} months (50 years) to pay off a principal of ${principal:,.2f} \"\n",
    "            f\"with an annual interest rate of {annual_interest_rate}% and a monthly payment of ${monthly_payment:,.2f}. \"\n",
    "            \"You might consider increasing your monthly payment.\"\n",
    "        )\n",
    "    else:\n",
    "        years = months / 12\n",
    "        return (\n",
    "            f\"To pay off a principal of ${principal:,.2f} with an annual interest rate of {annual_interest_rate}% \"\n",
    "            f\"and a monthly payment of ${monthly_payment:,.2f}:\\n\"\n",
    "            f\"- Estimated time to pay off: {months} months ({years:.1f} years)\\n\"\n",
    "            f\"- Estimated total interest paid: ${total_interest_paid:,.2f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_investment_planning_advice(input_str: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Provides general advice on investment planning.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Tool 'get_investment_planning_advice' called with input: {input_str}\")\n",
    "    return (\n",
    "        \"Investment planning involves setting financial goals and creating a strategy to achieve them through investments. Key aspects include:\\n\"\n",
    "        \"- **Define Your Goals:** What are you saving for? (e.g., retirement, down payment, education)\\n\"\n",
    "        \"- **Assess Risk Tolerance:** How comfortable are you with market fluctuations? This influences your asset allocation.\\n\"\n",
    "        \"- **Diversification:** Spreading investments across different asset classes (stocks, bonds, real estate) to reduce risk.\\n\"\n",
    "        \"- **Long-term vs. Short-term:** Tailor investments based on your timeline.\\n\"\n",
    "        \"- **Regular Contributions:** Consistency is often key to compounding returns.\\n\"\n",
    "        \"It's often recommended to consult a financial advisor for personalized investment planning.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Define LangChain Tools ---\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"FinancialLiteracyRetriever\",\n",
    "        func=retrieve_and_answer,\n",
    "        description=\"Useful for answering specific financial literacy questions by retrieving information from a knowledge base about topics like 401k, IRA, credit scores, mortgages, etc. Input should be a concise financial literacy question.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"SavingsAdvisor\",\n",
    "        func=recommend_savings,\n",
    "        description=\"Calculates a recommended savings amount based on provided monthly income and spending (e.g., 'income=3000, spending=2000'). If numbers are not provided, it gives general savings guidelines and prompts for input. Use this when the user asks about how much they should save or for personalized savings recommendations.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"BudgetingTemplateInfo\",\n",
    "        func=get_budgeting_templates,\n",
    "        description=\"Provides information about different types of budgeting templates and methods. Use this when the user asks about budgeting templates, how to start a budget, or tools for budgeting.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"ExpenseTrackerInfo\",\n",
    "        func=get_expense_tracker_info,\n",
    "        description=\"Explains what an expense tracker is and its benefits. Use this when the user asks about tracking expenses or managing spending.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"DebtCalculator\", # Renamed for clarity\n",
    "        func=calculate_debt_details, # Points to the new calculation function\n",
    "        description=\"Calculates the estimated time to pay off a debt and total interest paid. Requires specific inputs: 'principal=<amount>, interest_rate=<percentage>, monthly_payment=<amount>'. Use this when the user asks to calculate debt, loan payoff time, or total interest.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"InvestmentPlanningAdvisor\",\n",
    "        func=get_investment_planning_advice,\n",
    "        description=\"Offers general advice and principles for investment planning. Use this when the user asks about how to plan investments, investment strategies, or getting started with investing.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# --- Setup LangChain Agent ---\n",
    "logging.info(\"Setting up LangChain Agent...\")\n",
    "\n",
    "# Initialize the LLM for the agent itself\n",
    "# Use gpt-4o as the orchestrator for the agent's reasoning\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7, openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Add memory for conversational context\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Define the agent's prompt for create_openai_tools_agent\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a friendly and helpful financial literacy chatbot. Your goal is to assist users with their questions about personal finance, investing, debt management, budgeting, and savings. You have several specialized tools to help you find information and provide advice. When a calculation is requested, ensure you ask for all necessary numerical inputs clearly, specifying the format (e.g., 'monthly income is 3000, spending is 2000' for savings, or 'principal=10000, interest_rate=5, monthly_payment=200' for debt calculation).\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"), # This is where the agent's internal thought process will be injected\n",
    "])\n",
    "\n",
    "\n",
    "# Create the OpenAI Tools agent\n",
    "# This agent type is generally more robust with tool usage and structured outputs.\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "# Create the Agent Executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory, handle_parsing_errors=True)\n",
    "\n",
    "logging.info(\"LangChain Agent setup complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to Financial Literacy Chatbot (LangChain Agent Demo). Type 'exit' to quit.\")\n",
    "    if not chunks or not chunk_embeddings:\n",
    "        print(\"Chatbot cannot start due to missing data. Please check logs for errors.\")\n",
    "    else:\n",
    "        while True:\n",
    "            query = input(\"\\nAsk your question: \")\n",
    "            if query.lower() == \"exit\":\n",
    "                break\n",
    "            try:\n",
    "                # The agent_executor handles the entire conversation\n",
    "                response = agent_executor.invoke({\"input\": query})\n",
    "                print(f\"\\nðŸ’¬ Chatbot:\\n{response['output']}\")\n",
    "            except Exception as e:\n",
    "                \n",
    "                logging.error(f\"Error during agent execution: {e}\")\n",
    "                print(\"I apologize, I encountered an error trying to answer your question. Please try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb4344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d39956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
