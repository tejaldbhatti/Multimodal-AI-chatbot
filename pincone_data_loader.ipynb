{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275e8536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 17:49:29,048 - INFO - Initialized OpenAIEmbeddings model.\n",
      "2025-06-30 17:49:29,054 - INFO - Initialized Pinecone client.\n",
      "2025-06-30 17:49:31,365 - INFO - Successfully read and cleaned 76 transcript files.\n",
      "2025-06-30 17:49:31,368 - INFO - Splitting text into chunks with size 500 and overlap 100...\n",
      "2025-06-30 17:49:32,389 - INFO - Successfully loaded and converted 2139 text chunks to LangChain Documents.\n",
      "2025-06-30 17:49:32,392 - INFO - Starting Pinecone data loading process...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 2139 chunks from transcripts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 17:49:34,214 - INFO - Connecting to Pinecone index: financial-literacy-chatbot.\n",
      "2025-06-30 17:49:36,787 - INFO - Pinecone index 'financial-literacy-chatbot' already contains 2139 vectors. Skipping embedding upload.\n",
      "2025-06-30 17:49:36,788 - INFO - Pinecone data loading process complete. Index is ready.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key (start): pcsk_4rM ...\n",
      "Environment: us-east-1\n",
      "Available Indexes: [{\n",
      "    \"name\": \"financial-literacy-chatbot\",\n",
      "    \"metric\": \"cosine\",\n",
      "    \"host\": \"financial-literacy-chatbot-okahzuc.svc.aped-4627-b74a.pinecone.io\",\n",
      "    \"spec\": {\n",
      "        \"serverless\": {\n",
      "            \"cloud\": \"aws\",\n",
      "            \"region\": \"us-east-1\"\n",
      "        }\n",
      "    },\n",
      "    \"status\": {\n",
      "        \"ready\": true,\n",
      "        \"state\": \"Ready\"\n",
      "    },\n",
      "    \"vector_type\": \"dense\",\n",
      "    \"dimension\": 1536,\n",
      "    \"deletion_protection\": \"disabled\",\n",
      "    \"tags\": null\n",
      "}, {\n",
      "    \"name\": \"question-answering\",\n",
      "    \"metric\": \"cosine\",\n",
      "    \"host\": \"question-answering-okahzuc.svc.aped-4627-b74a.pinecone.io\",\n",
      "    \"spec\": {\n",
      "        \"serverless\": {\n",
      "            \"cloud\": \"aws\",\n",
      "            \"region\": \"us-east-1\"\n",
      "        }\n",
      "    },\n",
      "    \"status\": {\n",
      "        \"ready\": true,\n",
      "        \"state\": \"Ready\"\n",
      "    },\n",
      "    \"vector_type\": \"dense\",\n",
      "    \"dimension\": 384,\n",
      "    \"deletion_protection\": \"disabled\",\n",
      "    \"tags\": null\n",
      "}, {\n",
      "    \"name\": \"abstractive-question-answering\",\n",
      "    \"metric\": \"cosine\",\n",
      "    \"host\": \"abstractive-question-answering-okahzuc.svc.aped-4627-b74a.pinecone.io\",\n",
      "    \"spec\": {\n",
      "        \"serverless\": {\n",
      "            \"cloud\": \"aws\",\n",
      "            \"region\": \"us-east-1\"\n",
      "        }\n",
      "    },\n",
      "    \"status\": {\n",
      "        \"ready\": true,\n",
      "        \"state\": \"Ready\"\n",
      "    },\n",
      "    \"vector_type\": \"dense\",\n",
      "    \"dimension\": 768,\n",
      "    \"deletion_protection\": \"disabled\",\n",
      "    \"tags\": null\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() # This line is crucial for loading  .env file\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "# prepare_chunks.py is a separate file that handles reading, cleaning, and chunking transcripts.\n",
    "from prepare_chunks import read_and_chunk_transcripts\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Pinecone Imports\n",
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import PineconeApiException\n",
    "\n",
    "# --- Configure logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Initialize OpenAI client (for embeddings) ---\n",
    "try:\n",
    "    # OpenAI client is implicitly used by OpenAIEmbeddings, but explicitly initializing\n",
    "    # here can help with early error detection for the API key.\n",
    "    import openai\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai.api_key:\n",
    "        raise ValueError(\"OPENAI_API_KEY environment variable not set.\")\n",
    "except ValueError as e:\n",
    "    logging.error(f\"Configuration Error: {e}\")\n",
    "    exit(\"Exiting: OpenAI API key is missing. Please set OPENAI_API_KEY environment variable.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error initializing OpenAI API key: {e}\")\n",
    "    exit(\"Exiting: Failed to set OpenAI API key.\")\n",
    "\n",
    "\n",
    "# --- Initialize LangChain's OpenAIEmbeddings ---\n",
    "try:\n",
    "    embeddings_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    logging.info(\"Initialized OpenAIEmbeddings model.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error initializing OpenAIEmbeddings: {e}\")\n",
    "    exit(\"Exiting: Failed to initialize OpenAIEmbeddings. Check API key.\")\n",
    "\n",
    "# --- Pinecone Configuration ---\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\") # e.g., \"us-east-1\" or \"gcp-starter\"\n",
    "INDEX_NAME = \"financial-literacy-chatbot\" # Your chosen Pinecone index name\n",
    "\n",
    "if not PINECONE_API_KEY or not PINECONE_ENVIRONMENT:\n",
    "    logging.error(\"Pinecone API key or environment not set. Please add PINECONE_API_KEY and PINECONE_ENVIRONMENT to your .env file.\")\n",
    "    exit(\"Exiting: Pinecone credentials missing.\")\n",
    "\n",
    "try:\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
    "    logging.info(\"Initialized Pinecone client.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error initializing Pinecone client: {e}\")\n",
    "    exit(\"Exiting: Failed to initialize Pinecone. Check API key and environment.\")\n",
    "\n",
    "# --- Data Loading, Cleaning, and Chunking (using prepare_chunks.py) ---\n",
    "chunks: List[Document] = [] # Initialize chunks list as list of Document\n",
    "try:\n",
    "    raw_chunks = read_and_chunk_transcripts('transcripts/')\n",
    "    if not raw_chunks:\n",
    "        logging.warning(\"No chunks read from 'transcripts/'. Ensure files exist and content is processed.\")\n",
    "        exit(\"Exiting: No transcript chunks found.\")\n",
    "\n",
    "    # Convert raw string chunks to LangChain Document objects\n",
    "    chunks = [Document(page_content=chunk) for chunk in raw_chunks]\n",
    "    logging.info(f\"Successfully loaded and converted {len(chunks)} text chunks to LangChain Documents.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error reading, cleaning, or chunking transcripts: {e}\")\n",
    "    exit(\"Exiting: Failed to process transcripts. Check 'prepare_chunks.py' and 'transcripts/' directory.\")\n",
    "\n",
    "# --- Pinecone Index Setup and Embedding ---\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"Starting Pinecone data loading process...\")\n",
    "    try:\n",
    "        # Check if index exists by listing all indexes\n",
    "        existing_indexes = pc.list_indexes()\n",
    "        \n",
    "        index_exists = False\n",
    "        for idx_info in existing_indexes:\n",
    "            if isinstance(idx_info, dict) and idx_info.get('name') == INDEX_NAME:\n",
    "                index_exists = True\n",
    "                break\n",
    "            elif hasattr(idx_info, 'name') and idx_info.name == INDEX_NAME:\n",
    "                index_exists = True\n",
    "                break\n",
    "\n",
    "        if not index_exists:\n",
    "            logging.info(f\"Creating Pinecone index: {INDEX_NAME} with ServerlessSpec (cloud='aws', region='{PINECONE_ENVIRONMENT}').\")\n",
    "            try:\n",
    "                pc.create_index(\n",
    "                    name=INDEX_NAME,\n",
    "                    dimension=1536, # Dimension for text-embedding-ada-002\n",
    "                    metric='cosine',\n",
    "                    spec=ServerlessSpec(cloud=\"aws\", region=PINECONE_ENVIRONMENT)\n",
    "                )\n",
    "                logging.info(f\"Pinecone index '{INDEX_NAME}' created successfully.\")\n",
    "            except PineconeApiException as e_create_api:\n",
    "                if e_create_api.status == 409: # Catch ALREADY_EXISTS specifically\n",
    "                    logging.warning(f\"Pinecone index '{INDEX_NAME}' already exists (caught 409 Conflict during create_index). Proceeding to connect.\")\n",
    "                    index_exists = True # Mark as existing\n",
    "                else:\n",
    "                    raise e_create_api # Re-raise if it's another API error\n",
    "\n",
    "        if index_exists:\n",
    "            logging.info(f\"Connecting to Pinecone index: {INDEX_NAME}.\")\n",
    "            index = pc.Index(INDEX_NAME)\n",
    "\n",
    "            # Check if the index is empty. If so, upload embeddings.\n",
    "            \n",
    "            if index.describe_index_stats().total_vector_count == 0:\n",
    "                logging.info(\"Existing Pinecone index is empty. Proceeding with initial embedding upload.\")\n",
    "                BATCH_SIZE = 100 # Adjust batch size based on your data and Pinecone limits\n",
    "                for i in range(0, len(chunks), BATCH_SIZE):\n",
    "                    batch = chunks[i:i + BATCH_SIZE]\n",
    "                    logging.info(f\"Processing batch {i//BATCH_SIZE + 1}/{(len(chunks) + BATCH_SIZE - 1) // BATCH_SIZE} ({len(batch)} documents)...\")\n",
    "                    PineconeVectorStore.from_documents(\n",
    "                        documents=batch,\n",
    "                        embedding=embeddings_model,\n",
    "                        index_name=INDEX_NAME\n",
    "                    )\n",
    "                    logging.info(f\"Uploaded batch starting with document {i} to Pinecone.\")\n",
    "                logging.info(f\"Finished uploading all embeddings to Pinecone index '{INDEX_NAME}'. Total vectors now: {index.describe_index_stats().total_vector_count}\")\n",
    "            else:\n",
    "                logging.info(f\"Pinecone index '{INDEX_NAME}' already contains {index.describe_index_stats().total_vector_count} vectors. Skipping embedding upload.\")\n",
    "            \n",
    "            logging.info(\"Pinecone data loading process complete. Index is ready.\")\n",
    "\n",
    "        else:\n",
    "            logging.error(f\"Pinecone index '{INDEX_NAME}' could not be created or connected to.\")\n",
    "            exit(\"Exiting: Pinecone index setup failed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Critical error during Pinecone index setup and data loading: {e}\")\n",
    "        exit(\"Exiting: Failed to set up Pinecone index or load data. Ensure network connectivity, correct API key/environment, and valid Pinecone environment (e.g., 'us-west-2').\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"API Key (start):\", os.getenv(\"PINECONE_API_KEY\")[:8], \"...\")\n",
    "print(\"Environment:\", os.getenv(\"PINECONE_ENVIRONMENT\"))\n",
    "print(\"Available Indexes:\", pc.list_indexes())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234dd8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
